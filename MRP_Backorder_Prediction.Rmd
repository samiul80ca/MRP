---
title: "Predcting Product Backorder"
author: "Samiul_Islam_ID_500602494"
date: "July 14, 2018"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T)
```

## Problem definition:

When a customer orders a product which is not available in the store or temporary out of stock and the customer decides to wait until the product is available and promised to be shipped, then this scenario is called backorder of that specific product. If backorders are not handled promptly it will have a high impact on the respective company's revenue, share market price, customers' trusts and may end up with loosing the customer or sale order. On the other hand, the prompt actions to satisfy backorders put enormous pressure on different stages of supply chain which may exhaust the supply chain processes or may appear with extra labor costs and associated shipment costs. Now a day, many companies are trying to predict the backorders of per unit product by applying machine learning prediction process to overcome the associated tangible and intangible costs of backorders. In this work, we try to predict the backorder by employing different machine learning models. Though the performance of different models may vary on different length and types of datasets, in this work we try to focus on big data to compare the performances of those backorder prediction models to find out the suitable algorithm to solve backorder problems.

## Dataset:
The dataset intends to use for this project was first published in Kaggle competition (https://drive.google.com/open?id=1Ub10bN7Ud8UF1Dsw0JBd-3q-OUVEwWKI) which is divided into training and testing datasets. Each dataset contains 23 attributes with 1687862 and 242077 observations respectively for training and testing set. Following table shows the attribute information for both datasets. 

## No.	  Attribute	        Data type	    Description
    1	    sku	              Discrete	    Product ID
    2	    national_inv	    Discrete	    Current inventory level of different products
    3	    lead_time	        Discrete	    The time taken from release of an order to production and shipment
    4	    in_transit_qty	  Discrete	    Quantity of product in transit from source
    5	    forecast_3_month	Discrete	    Forecasted sales for next 3 months
    6	    forecast_6_month	Discrete	    Forecasted sales for next 6 months
    7	    forecast_9_month	Discrete	    Forecasted sales for next 9 months
    8	    sales_1_month	    Discrete	    Sales quantity for the prior 1 month
    9	    sales_3_month	    Discrete	    Sales quantity for the prior 3 months
    10	  sales_6_month	    Discrete	    Sales quantity for the prior 6 months
    11	  sales_9_month	    Discrete	    Sales quantity for the prior 9 months
    12	  min_bank	        Discrete	    Minimum recommended amount in stock
    13	  potential_issue	  Binary	      Identified issue of products
    14	  pieces_past_due	  Discrete	    Products overdue from source
    15	  perf_6_month_avg	Discrete	    Source average performance in last 6 months
    16	  perf_12_month_avg	Discrete	    Source average performance in last 12 months
    17	  local_bo_qty	    Discrete	    Amount of overdue stock orders
    18	  deck_risk	        Binary	      Product risk flag
    19	  oe_constraint	    Binary	      Product risk flag
    20	  ppap_risk	        Binary	      Product risk flag
    21	  stop_auto_buy	    Binary	      Product risk flag
    22	  rev_stop	        Binary	      Product risk flag
    23	  went_on_backorder	Binary	      Product actually went on backorder
[Binary data types:]     

## Research question:
Which machine learning model is feasible to predict future backorder that can be implemented as a part of inventory control?

```{r}
setwd("E:/SAMIUL RYERSON/MRP Project/product backorder/Backorder Prediction")
getwd()
```

```{r, loading required packages}
#-----------------------------------------Initial Setup----------------------------------------------#
#====================================================================================================#
#create a function to check for installed packages and install them if they are not installed#
install <- function(packages){
  new.packages <- packages[!(packages %in% installed.packages()[, "Package"])]
  if (length(new.packages)) 
    install.packages(new.packages, dependencies = TRUE)
  sapply(packages, require, character.only = TRUE)
}

# usage
required.packages <- c("caret","dplyr","unbalanced","scales", "pROC", "DMwR", "broom", "ggcorrplot","matrixStats", "tidyselect","ggplot2", "tidyquant", "modelr", "gridExtra", "grid","zoo", "magrittr", "pipeR")
install(required.packages)
options(na.action = na.warn)
```


```{r}
library('tidyquant')  # Loads tidyverse and custom ggplot themes
library("unbalanced") # Methods for dealing with unbalanced data sets
```


```{r}
# The following two commands remove any previously installed H2O packages for R.
if ("package:h2o" %in% search()) { detach("package:h2o", unload=TRUE) }
if ("h2o" %in% rownames(installed.packages())) { remove.packages("h2o") }
```

```{r,  downloading packages that H2O depends on.}
pkgs <- c("RCurl","jsonlite")
for (pkg in pkgs) {
if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
}
```

```{r}
# Now we download, install and initialize the H2O package for R.
install.packages("h2o", type="source", repos="http://h2o-release.s3.amazonaws.com/h2o/rel-wright/3/R")
```

```{r, loading H2O and start up an H2O cluster}

library(h2o)
h2o.init()
```


```{r, Data Loading}
train_data = read.csv("E:/SAMIUL RYERSON/MRP Project/product backorder/backorder data/Kaggle_Training_Dataset_v2.csv", header = T)
test_data = read.csv("E:/SAMIUL RYERSON/MRP Project/product backorder/backorder data/Kaggle_Test_Dataset_v2.csv", header = T)
```

## Data exploration

```{r, checking the data structures, echo=FALSE}
str(train_data)
```


```{r}
str(test_data)
```
both data sets contain a mix of features with floating point, integer and string values. The trainig dataset has 1687861 observations of 23  variables and the testing dataset has 242076 observations of 23 variables.  

```{r, checking the data summary, echo=FALSE}
summary(train_data)
```

We can see from the summary of the training dataset we can observe that the first column SKU which is known as the stock keeping unit, has 1687861 unique values. That means, sku has unique values for each row of data. As this attribute is used for indexing purpose, we can ignore this column in our model.  
```{r}
length(train_data$sku)
length(unique(train_data$sku))
```
```{r, checking for the empty record/value in each column}
is.null(train_data)
is.null(test_data)
```


```{r, checking for the missing values(NA) in each column}
colSums(is.na(train_data))
colSums(is.na(test_data))
```

In both datasets, we have missing values for the 'lead_time' feature. In the training dataset, there are 100894 missing values in lead_time which is 5.98% of the training data. Whereas in the testing dataset we have 14725 missing values which is 6.08% of the testing dataset. We have assumed that the missing values are put as 'NA' in these datasets.  

```{r, Replacing missing values with mean }
library('zoo')
write <- sapply(train_data, is.numeric)
train_data[write] <- lapply(train_data[write], na.aggregate)
```
We have replaced the NA values with the mean in the training dataset and we leave the testing data set as it is purposely.
```{r, cheking percentage of non-empty records in the datasets}
library(magrittr)
train_data %>% complete.cases() %>% sum()*100 / nrow(train_data)
#test_data %>% complete.cases() %>% sum()*100 / nrow(test_data)
```
Now our training dataset does not have any empty or NA values. From the summary, we have also observed that the number products those went on backorder is 11293 among the 1687861 observations.  which is relatively small to the prodcts those did not go on backorder. 
```{r}
table(train_data$went_on_backorder)
```

```{r}
barplot(main="Proportion of product backorder class", prop.table(table(train_data$went_on_backorder)))


```
The feature went_on_backorder contains 2 classes, "Yes" and "No". Yes class denotes that the product actually went on backorder. Unfortunately, we have only 0.669% data are from 'Yes' class and 99.33% data from 'No' class. From this we can say that our data set highly imbalanced. And, if we train our model with this imbalanced dataset, there is high possibility to have low model accuracy and efficiency. 



# Validation set
Though we have seperated training and testing datasets, we would like to create another validation dataset from the training dataset. The idea of this validation set is to tune the parameters of our classifier/model before actual exposed to the actual test set so that the model can perform the test with minimum error and work efficiently.

```{r, dividing the training set in to training and validation set}

percnt_div <- 0.80
n <- nrow(train_data)
partition_size <- floor(percnt_div * n)

set.seed(753)
train_index <- sample(1:n, size = partition_size)

validation_data <- train_data[-train_index,]
train_data <- train_data[train_index,]
```
 We have divided our training dataset into 80 and 20 percent randomly. Hence total observation of our training dataset becomes 1350288 and we have now a new validation dataset with 337573 observations.
 
```{r, Dataset mutation}
#install.packages("tidyselect")
require("tidyselect")
require("tidyverse")
```

```{r}

library(rlang)
library(dplyr)
data_mutation <- function(data) {
    data %>%
        select(-sku) %>%
        drop_na(national_inv) %>%
        mutate(lead_time = ifelse(is.na(lead_time), -99, lead_time)) %>%
        mutate_if(is.factor, .funs = function(x) ifelse(x == "Yes", 1, 0)) %>%
        mutate(went_on_backorder = as.factor(went_on_backorder))
}


training_dataset <- data_mutation(train_data) 
validation_dataset <- data_mutation(validation_data) 
testing_dataset  <- data_mutation(test_data)

str(training_dataset)
```

As the feature 'sku' is used only for the record indexing purpose, we have dropped this feature from our datasets. Also we want to make sure that the products' current inventory level contains a value.  

```{r, balancing the dataset using synthetic minority over-sampling technique}
library(smotefamily)
library(unbalanced)
input  <- training_dataset %>% select(-went_on_backorder)
output <- training_dataset$went_on_backorder 
balanced_training_data <- ubSMOTE(input, output, perc.over = 150, perc.under = 200, k = 7)
```

```{r}
# Recombine the synthetic balanced data
new_training_dataset <- bind_cols(as.tibble(balanced_training_data$X), tibble(went_on_backorder = balanced_training_data$Y))
```
We have replaced the 'Yes' with 1 and 'No' with 0 in our datasets.After applying the SMOTE, we have achieved 50-50 class values in our training dataset by tuning the perc.over and perc.under values. We have also used K nearest neighbour or KNN approach and in our case we have chosen the  nearest neighbour number as 7 when we have generated new artificial observations. 
```{r}
prop.table(table(new_training_dataset$went_on_backorder))

```
As this synthetically derived training set has lower observation numbers (36436) in compare to the actual training set observations(1350288), we have decided to examine another data balancing method for the experimental purpose. In this case, we have used Random Over-Sampling Examples known as ROSE. This technique has provided us almost perfect balancing of classes by keeping the number of observations same.
```{r}
library(ROSE)

set.seed(4021)
rose_train <- ROSE(went_on_backorder ~ ., data  = training_dataset)$data                         
prop.table(table(rose_train$went_on_backorder)) 
```


```{r}
h2o.no_progress()
```

Our data sets are in data frame format and h2o require the data in the h2o frame format. So we have converted the datasets in to h2o frame.

```{r}
h2o_train_data_smote <- as.h2o(new_training_dataset)
h2o_validation_data_smote <- as.h2o(validation_dataset)
h2o_test_data_smote  <- as.h2o(testing_dataset)
```

```{r, h2o modeling}

y <- "went_on_backorder"
x <- setdiff(names(h2o_train_data_smote), y)

h2o_model <- h2o.automl(
    x = x, 
    y = y,
    training_frame    = h2o_train_data_smote,
    validation_frame  = h2o_validation_data_smote,
    leaderboard_frame = h2o_test_data_smote,
    max_runtime_secs  = 90
)
```


```{r}
h2o_leader <- h2o_model@leader
```

```{r}
h2o_model_prediction <- h2o.predict(h2o_leader, newdata = h2o_test_data_smote)
as.tibble(h2o_model_prediction)
```

```{r, preformance measure }
performance_h2o_model <- h2o.performance(h2o_leader, newdata = h2o_test_data_smote) 
```

```{r, performance metric}
h2o.metric(performance_h2o_model) %>% as.tibble() %>% glimpse()
```

```{r, performance visualization using ROC or receiver operating chareacteristic}
library(tidyquant)
left_join(h2o.tpr(performance_h2o_model), h2o.fpr(performance_h2o_model)) %>%
    mutate(random_guess = fpr) %>%
    select(-threshold) %>%
    ggplot(aes(x = fpr)) + 
    geom_area(aes(y = tpr, fill = "Area Under the Curve"), alpha = 0.5) +
    geom_point(aes(y = tpr, color = "True Positive Rates"), alpha = 0.25) +
    geom_line(aes(y = random_guess, color = "Random Guess"), size = 1, linetype = 2) +
    theme_tq() +
    scale_color_manual(
        name = "Key", 
        values = c("True Positive Rates" = palette_dark()[[1]],
                   "Random Guess" = palette_dark()[[2]])
        ) +
    scale_fill_manual(name = "Fill", values = c("Area Under the Curve" = palette_dark()[[5]])) +
    labs(title = "ROC Curve of H2O Prediction Model", subtitle = "H2O Model performance is more efficient than random guessing") + xlab("False Positive Rates")+ ylab("True Positive Rates")+
    annotate("text", x = 0.25, y = 0.65, label = "More efficient than guessing") +
    annotate("text", x = 0.75, y = 0.25, label = "Less efficient than guessing")
```

```{r, models AUC}
h2o.auc(performance_h2o_model)
```

```{r}
# predictions are based on p1_cutoff
as.tibble(h2o_model_prediction)
```


```{r}
# Algorithm uses p1_cutoff that maximizes F1
h2o.F1(performance_h2o_model) %>%
    as.tibble() %>%
    filter(f1 == max(f1))
```
```{r}
 #Full list of thresholds at various performance metrics
performance_h2o_model@metrics$max_criteria_and_metric_scores
```




```{r}
# Plot recall and precision vs threshold, visualize inventory strategy effect
left_join(h2o.recall(performance_h2o_model), h2o.precision(performance_h2o_model)) %>%
    rename(recall = tpr) %>%
    gather(key = key, value = value, -threshold) %>%
    ggplot(aes(x = threshold, y = value, color = key)) +
    geom_point(alpha = 0.5) +
    scale_color_tq() +
    theme_tq() +
    labs(title = 'Precision and Recall vs Cutoff ("Yes" Threshold)',
         subtitle = "As the cutoff increases from zero, inventory strategy becomes more conservative",
         x = 'Cutoff (Probability above which we predict went_on_backorder = "Yes")',
         y = "Precision and Recall Values"
         ) +
    # p>=0
    geom_vline(xintercept = 0, color = palette_light()[[3]], size = 1) +
    annotate("text", x = 0.12, y = 0.75, size = 3,
             label = 'p1 >= 0: "Yes"\nInventory\nEverything') +
    geom_segment(x = 0, y = 0.7, xend = 0.02, yend= 0.72, color = palette_light()[[3]], size = 1) +
    # p>=0.25
    geom_vline(xintercept = 0.25, color = palette_light()[[3]], size = 1) +
    annotate("text", x = 0.37, y = 0.35, size = 3,
             label = 'p1 >= 0.25: "Yes"\nInventory Anything\nWith Chance\nof Backorder') +
    geom_segment(x = 0.25, y = 0.30, xend = 0.27, yend= 0.32, color = palette_light()[[3]], size = 1) +
    # p>=0.5
    geom_vline(xintercept = 0.5, color = palette_light()[[3]], size = 1) +
    annotate("text", x = 0.62, y = 0.75, size = 3,
             label = 'p1 >= 0.50: "Yes"\nInventory\nProbability\nSplit 50/50') +
    geom_segment(x = 0.5, y = 0.70, xend = 0.52, yend= 0.72, color = palette_light()[[3]], size = 1) +
    # p>=0.75
    geom_vline(xintercept = 0.75, color = palette_light()[[3]], size = 1) +
    annotate("text", x = 0.87, y = 0.75, size = 3,
             label = 'p1 >= 0.75: "Yes"\nInventory Very\nConservatively\n(Most Likely Backorder)') +
    geom_segment(x = 0.75, y = 0.70, xend = 0.77, yend= 0.72, color = palette_light()[[3]], size = 1) +
    # p>=1
    geom_vline(xintercept = 1, color = palette_light()[[3]], size = 1) +
    annotate("text", x = 0.87, y = 0.22, size = 3,
             label = 'p1 >= 1.00: "Yes"\nInventory Nothing') +
    geom_segment(x = 1.00, y = 0.23, xend = 0.98, yend= 0.21, color = palette_light()[[3]], size = 1) 
```


```{r, confusion matrix}
#  As from the model metrics we got maximum F1 thresold 0.841836, we assume that p1_cutoff = 0.84  
h2o.confusionMatrix(performance_h2o_model)
```


```{r, We also can get expected rates by cutoff}

expected_rates <- h2o.metric(performance_h2o_model) %>%
    as.tibble() %>%
    select(threshold, tpr, fpr, fnr, tnr)
expected_rates
```


```{r, Cost/benefit for first item}

first_item <- h2o_model_prediction %>%
    as.tibble() %>%
    slice(1) %>%
    add_column(
        cb_tn = 0,
        cb_tp = 400,
        cb_fp = -10,
        cb_fn = 0
        )
first_item
```


```{r}
# Function to calculate expected profit
calc_expected_profit <- function(p1, cb_tp, cb_fp) {
    # p1    = Set of predictions with "predict", "p0", and "p1" columns
    # cb_tp = Benefit (profit) from true positive (correctly identifying backorder)
    # cb_fp = Cost (expense) from false negative (incorrectly inventorying)
    
    tibble(
        p1    = p1,
        cb_tp = cb_tp,
        cb_fp = cb_fp
        ) %>%
        # Add in expected rates
        mutate(expected_rates = list(expected_rates)) %>%
        unnest() %>%
        mutate(
            expected_profit = p1 * (tpr * cb_tp) + (1 - p1) * (fpr * cb_fp)
        ) %>%
        select(threshold, expected_profit)
}

# Investigate a expected profit of item with low probability of backorder
hypothetical_low <- calc_expected_profit(p1 = 0.01, cb_tp = 400, cb_fp = -10)
hypothetical_low_max <- filter(hypothetical_low, expected_profit == max(expected_profit))

hypothetical_low %>%
    ggplot(aes(threshold, expected_profit, color = expected_profit)) + ylab("Expected Profit per Unit") + xlab("Thresold value")+
    geom_point() +
    geom_hline(yintercept = 0, color = "red") +
    geom_vline(xintercept = hypothetical_low_max$threshold, color = palette_light()[[1]]) +
    theme_tq() +
    scale_color_continuous(low = palette_light()[[1]], high = palette_light()[[2]]) +
    labs(title = "Expected Profit Curve for Low Backorder Probability" ,
         subtitle = "When probability of backorder is low, threshold increases inventory conservatism",
         caption  = paste0('Maximum threshold = ', hypothetical_low_max$threshold %>% round (2))
         )

```


```{r}
# Investigate a expected profit of item with high probability of backorder
hypothetical_high <- calc_expected_profit(p1 = 0.8, cb_tp = 400, cb_fp = -10)
hypothetical_high_max <- filter(hypothetical_high, expected_profit == max(expected_profit))

hypothetical_high %>%
    ggplot(aes(threshold, expected_profit, color = expected_profit)) + ylab("Expected Profit") + xlab("Thresold value")+
    geom_point() +
    geom_hline(yintercept = 0, color = "red") +
    geom_vline(xintercept = hypothetical_high_max$threshold, color = palette_light()[[1]]) +
    theme_tq() +
    scale_color_continuous(low = palette_light()[[1]], high = palette_light()[[2]]) +
    labs(title = "Expected Profit Curve for High Backorder Probability",
         subtitle = "When the probability of backorder of items are high, ",
         caption  = paste0('Maximum threshold = ', hypothetical_high_max$threshold %>% round (2))
         )
```


```{r}
# Generating Ten Hypothetical Items
ten_items <- tribble(
    ~"item", ~"p1",  ~"cb_tp", ~"cb_fp", ~"safety_stock",
    1,       0.02,      10,    -0.75,    100,
    2,       0.09,      7.5,   -0.75,    35,
    3,       0.65,      8.5,   -0.75,    75,
    4,       0.01,      25,    -2.5,     50,
    5,       0.10,      15,    -0.5,     150,
    6,       0.09,      400,   -25,      5,
    7,       0.05,      17.5,  -5,       25,
    8,       0.01,      200,   -9,       75,
    9,       0.11,      25,    -2,       50,
    10,      0.13,      11,    -0.9,     150
)
ten_items
```


```{r}
# Calculation of expected profit for each of the ten items at each threshold
extended_expected_profit_ten_items <- ten_items %>%
    # pmap to map calc_expected_profit() to each item
    mutate(expected_profit = pmap(.l = list(p1, cb_tp, cb_fp), .f = calc_expected_profit)) %>%
    unnest() %>%
    rename(expected_profit_per_unit = expected_profit) %>%
    # Calculate 100% safety stock repurchase and sell
    mutate(expected_profit_extended = expected_profit_per_unit * 1 * safety_stock) %>%
    select(item, p1, threshold, expected_profit_extended) 
extended_expected_profit_ten_items
```


```{r}
# Visualizing Expected Profit 
extended_expected_profit_ten_items %>%
    ggplot(aes(threshold, expected_profit_extended, 
               color = factor(item)), 
               group = item) + ylab("Expected Extended Profits") + xlab("Thresold Value")+
    geom_line(size = 1) +
    theme_tq() +
    scale_color_tq() +
    labs(
        title = "Expected Extended Profit Curves",
        subtitle = "Visualizing the expected profit curves for each item extended for backorder-prevention quantity to be purchased and sold",
        color = "Item No." 
    )
```


```{r, Total extended expected profit based on thresold}
total_expected_profit_ten_items <- extended_expected_profit_ten_items %>%
    group_by(threshold) %>%
    summarise(expected_profit_total = sum(expected_profit_extended)) 

# Get maximum (optimal) threshold
max_expected_profit <- total_expected_profit_ten_items %>%
    filter(expected_profit_total == max(expected_profit_total))

# Visualize the total expected profit curve
total_expected_profit_ten_items %>%
    ggplot(aes(threshold, expected_profit_total)) + xlab("Thresold value") + ylab("Aggregated expected profit")+
    geom_line(size = 1, color = palette_light()[[1]]) +
    geom_vline(xintercept = max_expected_profit$threshold, color = palette_light()[[1]]) +
    theme_tq() +
    scale_color_tq() +
    labs(
        title = "Expected Aggregated Profit Curve",
        subtitle = "We can achieve optimal strategy by summing up the curves by threshold",
        caption  = paste0('Maximum threshold = ', max_expected_profit$threshold %>% round (2))
    )
```

```{r}
#Install and load Boruta package
#install.packages(Boruta)
library(Boruta)

# Run Boruta Algorithm
set.seed(456)
boruta <- Boruta(went_on_backorder~., data = train_data, doTrace = 2)
print(boruta)
plot(boruta)
```